[2023-07-27 00:52:24,199] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/cluster_home/cao/conda/envs/pegasus_example/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so
CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 118
CUDA SETUP: Loading binary /home/cluster_home/cao/conda/envs/pegasus_example/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...
Max source length: 512
Max target length: 67
Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']
Starting to train...
{'loss': 2.2286, 'learning_rate': 4.8286732456140355e-05, 'epoch': 0.07}
{'loss': 2.1733, 'learning_rate': 4.657346491228071e-05, 'epoch': 0.14}
{'loss': 2.1577, 'learning_rate': 4.486019736842105e-05, 'epoch': 0.21}
{'loss': 2.1398, 'learning_rate': 4.3146929824561405e-05, 'epoch': 0.27}
{'loss': 2.1222, 'learning_rate': 4.143366228070176e-05, 'epoch': 0.34}
{'loss': 2.1178, 'learning_rate': 3.972039473684211e-05, 'epoch': 0.41}
{'loss': 2.1068, 'learning_rate': 3.8007127192982455e-05, 'epoch': 0.48}
{'loss': 2.1086, 'learning_rate': 3.629385964912281e-05, 'epoch': 0.55}
{'loss': 2.0962, 'learning_rate': 3.458059210526316e-05, 'epoch': 0.62}
{'loss': 2.0924, 'learning_rate': 3.286732456140351e-05, 'epoch': 0.69}
{'loss': 2.1067, 'learning_rate': 3.115405701754386e-05, 'epoch': 0.75}
{'loss': 2.0765, 'learning_rate': 2.944078947368421e-05, 'epoch': 0.82}
{'loss': 2.0808, 'learning_rate': 2.7727521929824562e-05, 'epoch': 0.89}
{'loss': 2.0748, 'learning_rate': 2.6014254385964915e-05, 'epoch': 0.96}
{'eval_loss': 1.9500731229782104, 'eval_rouge1': 31.3864, 'eval_rouge2': 12.0096, 'eval_rougeL': 25.5527, 'eval_rougeLsum': 26.9826, 'eval_gen_len': 18.999694796276515, 'eval_runtime': 592.5261, 'eval_samples_per_second': 11.059, 'eval_steps_per_second': 0.692, 'epoch': 1.0}
{'loss': 2.0304, 'learning_rate': 2.4300986842105264e-05, 'epoch': 1.03}
{'loss': 1.9922, 'learning_rate': 2.2587719298245616e-05, 'epoch': 1.1}
{'loss': 1.9803, 'learning_rate': 2.0874451754385965e-05, 'epoch': 1.17}
{'loss': 1.9803, 'learning_rate': 1.9161184210526317e-05, 'epoch': 1.23}
{'loss': 1.9836, 'learning_rate': 1.7447916666666666e-05, 'epoch': 1.3}
{'loss': 1.9868, 'learning_rate': 1.573464912280702e-05, 'epoch': 1.37}
{'loss': 1.9723, 'learning_rate': 1.4021381578947367e-05, 'epoch': 1.44}
{'loss': 1.978, 'learning_rate': 1.230811403508772e-05, 'epoch': 1.51}
{'loss': 1.978, 'learning_rate': 1.059484649122807e-05, 'epoch': 1.58}
{'loss': 1.9863, 'learning_rate': 8.881578947368421e-06, 'epoch': 1.64}
{'loss': 1.978, 'learning_rate': 7.168311403508772e-06, 'epoch': 1.71}
{'loss': 1.976, 'learning_rate': 5.455043859649123e-06, 'epoch': 1.78}
{'loss': 1.98, 'learning_rate': 3.741776315789474e-06, 'epoch': 1.85}
{'loss': 1.9801, 'learning_rate': 2.028508771929825e-06, 'epoch': 1.92}
{'loss': 1.9769, 'learning_rate': 3.152412280701754e-07, 'epoch': 1.99}
{'eval_loss': 1.9339722394943237, 'eval_rouge1': 31.431, 'eval_rouge2': 12.024, 'eval_rougeL': 25.6231, 'eval_rougeLsum': 27.057, 'eval_gen_len': 18.999542194414772, 'eval_runtime': 591.7558, 'eval_samples_per_second': 11.074, 'eval_steps_per_second': 0.693, 'epoch': 2.0}
{'train_runtime': 24490.4502, 'train_samples_per_second': 9.532, 'train_steps_per_second': 0.596, 'train_loss': 2.04933384217714, 'epoch': 2.0}
